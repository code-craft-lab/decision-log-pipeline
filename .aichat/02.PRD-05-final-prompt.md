Jesteś doświadczonym menedżerem produktu, którego zadaniem jest stworzenie kompleksowego dokumentu wymagań produktu (PRD) w oparciu o poniższe opisy:

<project_description>
## Główny problem
OPA (Open Policy Agent) działa jako sidecar przy setkach mikro-serwisów w Kubernetes. Każda autoryzacja generuje decision log. Problemem jest obsługa decyzji OPA i utrwalenie ich w dwóch niezależnych miejscach. Pierwsze to long term storage. Drugi to real time access dla decyzji OPA.

## Najmniejszy zestaw funkcjonalności
- Obsługa odbioru decyzji z OPA za pośrednictwem protokołu HTTP
- Zapis decyzji OPA do Kafka
- Odczyt decyzji OPA z Kafka i zapisanie do long term storage S3
- Problem zapisu do S3 przenosi wiadomość na DLQ
- Odczyt decyzji OPA z Kafka i zapisanie do teal time storage OpenSearch
- Problem zapisu do OpenSearch przenosi wiadomość na DLQ

## Co NIE wchodzi w zakres MVP (Out-of-Scope)
- Wyszukiwanie i analiza w S3
- Back-fill historycznych logów
- PII masking/redaction
- Rozbudowana obserwowalność (tracing, latency histograms)
- Self-service UI
- GDPR delete-requests

## Kryteria sukcesu
- 99,99 % decyzji OPA zostaje utrwaonych w S3
- 99,99 % decyzji OPA z ostatnich 3 dni można wyszukać w OpenSearch
</project_description>

<project_details>
<conversation_summary>

<decisions>
1. Format logów: JSON array; pola nieistotne dla MVP.  
2. OPA wysyła batch co 60-120 s (lub szybciej); średnio 15 000 logów/min, szczyt 50 000/min; maks. 200 mln logów/miesiąc.  
3. Jedna decyzja: 2,5-3,5 kB; maks. rozmiar rekordu Kafka: 1 MB.  
4. Logi muszą trafić do OpenSearch w ≤ 1 min od wysłania przez OPA.  
5. Serwis HTTP potwierdza przyjęcie dopiero po publikacji batcha do Kafka.  
6. Kafka otrzymuje surowy JSON array; klucz partycji dowolny.  
7. Konsument Kafka zapisuje do S3 (gzip, ścieżka `s3://bucket/environment/product/`); retencja 20 lat; brak wersjonowania prefixu.  
8. Konsument Kafka indeksuje do OpenSearch; retencja 3 dni z automatycznym usunięciem.  
9. DLQ dla błędów zapisu; obsługa ręczna przez zespół projektu; dashboard/alerty zapewnia platforma.  
10. Bezpieczeństwo: uwierzytelnienie API Key (wiele kluczy w K8s Secrets); brak dodatkowego szyfrowania danych at-rest.  
11. Maskowanie/PII – brak w MVP.  
12. Metryki i obserwowalność dostarcza istniejąca platforma (poza zakresem projektu).  
13. OpenSearch cluster i infrastruktura poza zakresem projektu.
</decisions>

<matched_recommendations>
1. Zaplanować chunking po stronie producenta, gdy batch przekroczy limit 1 MB.
2. Zapewnić wsparcie wielu API Keys dla komunikacji pomiędzy OPA i producentem.
3. Zdefiniować playbook ręcznego re-process DLQ oraz SLO czasu reakcji.
</matched_recommendations>

<prd_planning_summary>
a. Główne wymagania funkcjonalne  
• Serwis HTTP przyjmujący batche decyzji z OPA (API Key auth, obsługa > 50 000 logów/min).  
• Publikacja batchy do Apache Kafka (≤ 1 MB).  
• Konsument 1: zapis do S3 w formacie gzip; trwałość danych 20 lat.  
• Konsument 2: indeksacja do OpenSearch; dostępność danych ≤ 60 s; automatyczne usunięcie po 3 dniach.  
• Mechanizm DLQ przenoszący problematyczne wiadomości; ręczna obsługa.

b. Kluczowe historie użytkownika / ścieżki  
• Operator bezpieczeństwa przegląda log w OpenSearch w ciągu minuty od zdarzenia.  
• Inżynier SRE odzyskuje utracone logi, pobierając batch z DLQ i ponownie przetwarzając do S3/OpenSearch.  
• System archiwizacji pobiera pliki gzip z S3 po dowolnym czasie do 20 lat wstecz.

c. Kryteria sukcesu i metryki  
• ≥ 99,99 % decyzji zapisanych w S3 (metryka write-success).  
• ≥ 99,99 % decyzji z ostatnich 3 dni dostępnych w OpenSearch w ≤ 60 s (metryka age).  
• Zero utraconych batchy podczas szczytu 50 000 logów/min.  
• DLQ = 0 nieprzetworzonych wiadomości > 24 h.

d. Nierozwiązane kwestie  
• Parametry rollover bundlingu gzip (czas vs. rozmiar).  
• Formalny playbook obsługi DLQ (SLO, procedura eskalacji).
</prd_planning_summary>

<unresolved_issues>
1. Ustalenie dokładnej strategii bundlingu gzip oraz harmonogramu rollover.
2. Projekt i implementacja wielu API Keys.
3. Opracowanie szczegółowego playbooka dla DLQ (odpowiedzialności, czas reakcji).
</unresolved_issues>

</conversation_summary>
</project_details>

Wykonaj następujące kroki, aby stworzyć kompleksowy i dobrze zorganizowany dokument:

1. Podziel PRD na następujące sekcje:
   a. Przegląd projektu
   b. Problem użytkownika
   c. Wymagania funkcjonalne
   d. Granice projektu
   e. Historie użytkownika
   f. Metryki sukcesu

2. W każdej sekcji należy podać szczegółowe i istotne informacje w oparciu o opis projektu i odpowiedzi na pytania wyjaśniające. Upewnij się, że:
   - Używasz jasnego i zwięzłego języka
   - W razie potrzeby podajesz konkretne szczegóły i dane
   - Zachowujesz spójność w całym dokumencie
   - Odnosisz się do wszystkich punktów wymienionych w każdej sekcji

3. Podczas tworzenia historyjek użytkownika i kryteriów akceptacji
   - Wymień WSZYSTKIE niezbędne historyjki użytkownika, w tym scenariusze podstawowe, alternatywne i skrajne.
   - Przypisz unikalny identyfikator wymagań (np. US-001) do każdej historyjki użytkownika w celu bezpośredniej identyfikowalności.
   - Uwzględnij co najmniej jedną historię użytkownika specjalnie dla bezpiecznego dostępu lub uwierzytelniania, jeśli aplikacja wymaga identyfikacji użytkownika lub ograniczeń dostępu.
   - Upewnij się, że żadna potencjalna interakcja użytkownika nie została pominięta.
   - Upewnij się, że każda historia użytkownika jest testowalna.

Użyj następującej struktury dla każdej historii użytkownika:
- ID
- Tytuł
- Opis
- Kryteria akceptacji

4. Po ukończeniu PRD przejrzyj go pod kątem tej listy kontrolnej:
   - Czy każdą historię użytkownika można przetestować?
   - Czy kryteria akceptacji są jasne i konkretne?
   - Czy mamy wystarczająco dużo historyjek użytkownika, aby zbudować w pełni funkcjonalną aplikację?
   - Czy uwzględniliśmy wymagania dotyczące uwierzytelniania i autoryzacji (jeśli dotyczy)?

5. Formatowanie PRD:
   - Zachowaj spójne formatowanie i numerację.
   - Nie używaj pogrubionego formatowania w markdown ( ** ).
   - Wymień WSZYSTKIE historyjki użytkownika.
   - Sformatuj PRD w poprawnym markdown.

Przygotuj PRD z następującą strukturą:

```markdown
# Dokument wymagań produktu (PRD) - {{app-name}}
## 1. Przegląd produktu
## 2. Problem użytkownika
## 3. Wymagania funkcjonalne
## 4. Granice produktu
## 5. Historyjki użytkowników
## 6. Metryki sukcesu
```

Pamiętaj, aby wypełnić każdą sekcję szczegółowymi, istotnymi informacjami w oparciu o opis projektu i nasze pytania wyjaśniające. Upewnij się, że PRD jest wyczerpujący, jasny i zawiera wszystkie istotne informacje potrzebne do dalszej pracy nad produktem.

Ostateczny wynik powinien składać się wyłącznie z PRD zgodnego ze wskazanym formatem w markdown, który zapiszesz w pliku docs/PRD.md